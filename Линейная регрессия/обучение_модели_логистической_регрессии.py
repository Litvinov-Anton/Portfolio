# -*- coding: utf-8 -*-
"""Обучение модели логистической регрессии.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GwkIhUygrfMGw_a2d0IV7jsLISD1dLLq

**Отнесение конфеты к классу с помощью логистической регрессии**
"""

# Commented out IPython magic to ensure Python compatibility.

# чтение данных, так как названия конфет уникальны, используем их в качестве индекса

import pandas as pd
DATA = pd.read_csv("/content/candy-data.csv", delimiter=',', index_col='competitorname')

# обучение модели будем проводить на данных, за исключением некоторых конфет

train_data = DATA.drop(['100 Grand','3 Musketeers','One dime','One quarter','Air Heads'])

# отбор данных для предикторов, удаление дввух последних столбцов, индекс не включается в данные автоматически.

X = pd.DataFrame(train_data.drop(['winpercent', 'Y'], axis=1))

# отбор столбца для отклика

y = pd.DataFrame(train_data['Y'])

# Обучение модели логистической регрессии

# подключение модели логистической регрессии из библиотеки sklearn
 
from sklearn.linear_model import LogisticRegression

# обучение модели
reg = LogisticRegression(random_state=2019, solver='lbfgs').fit(X, y.values.ravel())

# Предсказание результатов с помощью обученной модели

# предсказание для сладости, введенной вручную, вероятности указаны для классов 0 и 1 соответственно 

reg.predict_proba([[1, 1, 1, 0, 0, 1, 1, 1, 0, 0.64, 0.76]])

# array([[0.16929823, 0.83070177]])

# предсказание для сладости из таблицы

# выбор строки из таблицы

AirHeads = DATA.loc['Air Heads',:].to_frame().T

# отбор данных для предикторов и предсказание

reg.predict(AirHeads.drop(['winpercent', 'Y'], axis=1))

# array([0])

# Оценка модели с помощью тестовых данных

# чтение тестовых данных и отбор предикторов

test_data = pd.read_csv("/content/candy-data.csv", delimiter=',', index_col='competitorname')
X_test = pd.DataFrame(test_data.drop(['winpercent', 'Y'], axis=1))

# предсказание с помощью обученной модели, порог отсечения по умолчанию составляет 0.5

Y_pred = reg.predict(X_test)
Y_pred

# array([0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1])

# вероятности отнесения к 0 и 1 классу объектов тестовых данных соответствнно

Y_pred_probs = reg.predict_proba(X_test)
Y_pred_probs

# array([[0.72311341, 0.27688659],
#      [0.66492117, 0.33507883],
#      [0.66530382, 0.33469618],
#      [0.64424243, 0.35575757],
#      [0.2817487 , 0.7182513 ],
#      [0.3187884 , 0.6812116 ],
#      [0.31177263, 0.68822737],
#      [0.236561  , 0.763439  ],
#      [0.65296892, 0.34703108],
#      [0.64227911, 0.35772089],
#      [0.66110745, 0.33889255],
#      [0.84950158, 0.15049842],
#      [0.65443869, 0.34556131],
#      [0.40934211, 0.59065789],
#      [0.28409362, 0.71590638]])

# отбор вероятностей отнесения объектов к классу 1

Y_pred_probs_class_1 = Y_pred_probs[:, 1]
Y_pred_probs_class_1

# array([0.27688659, 0.33507883, 0.33469618, 0.35575757, 0.7182513 ,
#      0.6812116 , 0.68822737, 0.763439  , 0.34703108, 0.35772089,
#      0.33889255, 0.15049842, 0.34556131, 0.59065789, 0.71590638])

# отбор отклика Y из тестовых данных и преобразование в массив
Y_true = (test_data['Y'].to_frame().T).values.ravel()
Y_true

# array([0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1])

# подключение библиотеки для вычисления метрик

from sklearn import metrics
fpr, tpr, _ = metrics.roc_curve(Y_true, Y_pred)

# вычисляем AUC

metrics.roc_auc_score(Y_true, Y_pred_probs_class_1)

# 0.8799999999999999

# вычисление Recall

metrics.recall_score(Y_true, Y_pred)

# 0.6

# вычисление Precision

metrics.precision_score(Y_true, Y_pred)

# 0.5

# подключим библиотеки для визуализации

import matplotlib.pyplot as plt
# %matplotlib inline
metrics.plot_roc_curve(reg, X_test, Y_true, color='darkorange') 
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic example')
plt.legend(loc="lower right")
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.show()